"""
Retrain Model with User-Collected Data

This script retrains the migraine prediction model by combining:
1. Original training data
2. User-collected data from the training pool

Run this script periodically (e.g., weekly) after collecting sufficient user data.
"""

import pandas as pd
import os
import sys
from datetime import datetime
import shutil
from train_model import MigrainePredictionSystem

def retrain_model():
    print("\n" + "="*70)
    print("RETRAINING MODEL WITH USER DATA")
    print("="*70)
    
    # ============================================
    # 1. Load Original Training Data
    # ============================================
    print("\nğŸ“‚ Step 1: Loading original training data...")
    
    try:
        df_original = pd.read_excel('../junc2025sensordata.xlsx')
        
        # Parse if CSV-in-Excel format
        if len(df_original.columns) == 1:
            print("   Parsing CSV-formatted Excel file...")
            col_name = df_original.columns[0]
            header = col_name.split(',')
            df_original = df_original[col_name].str.split(',', expand=True)
            df_original.columns = header
            
            # Convert to numeric
            for col in df_original.columns:
                if col not in ['UserID']:
                    df_original[col] = pd.to_numeric(df_original[col], errors='coerce')
        
        print(f"   âœ“ Original data: {len(df_original)} records")
        print(f"   âœ“ Users: {df_original['UserID'].nunique()}")
        
        # Show migraine distribution
        migraine_dist = df_original['Migraine_today_0_or_1'].value_counts()
        print(f"   âœ“ Migraines: {migraine_dist.get(1, 0)} ({migraine_dist.get(1, 0)/len(df_original)*100:.1f}%)")
        print(f"   âœ“ No migraines: {migraine_dist.get(0, 0)} ({migraine_dist.get(0, 0)/len(df_original)*100:.1f}%)")
        
    except Exception as e:
        print(f"   âš ï¸  Could not load original data: {e}")
        print(f"   â†’ Will train on user data only")
        df_original = None
    
    # ============================================
    # 2. Load User Training Pool
    # ============================================
    print("\nğŸ“š Step 2: Loading user training pool...")
    
    training_pool_file = 'user_data/training_pool.csv'
    
    if not os.path.exists(training_pool_file):
        print(f"   âŒ Training pool not found at {training_pool_file}")
        print(f"\n   ğŸ’¡ No user data collected yet!")
        print(f"   â†’ Use store_temporal_data() to collect user data")
        print(f"   â†’ Each time a user confirms a migraine outcome, data is added")
        print(f"   â†’ Come back when you have at least 30-50 user records\n")
        return False
    
    try:
        df_pool = pd.read_csv(training_pool_file)
        
        print(f"   âœ“ Training pool: {len(df_pool)} records")
        print(f"   âœ“ Unique users: {df_pool['UserID'].nunique()}")
        
        # Show migraine distribution
        migraine_counts = df_pool['Migraine_today_0_or_1'].value_counts()
        print(f"   âœ“ Migraines: {migraine_counts.get(1, 0)} ({migraine_counts.get(1, 0)/len(df_pool)*100:.1f}%)")
        print(f"   âœ“ No migraines: {migraine_counts.get(0, 0)} ({migraine_counts.get(0, 0)/len(df_pool)*100:.1f}%)")
        
        # Check if enough data
        if len(df_pool) < 30:
            print(f"\n   âš ï¸  Warning: Only {len(df_pool)} records in training pool")
            print(f"   â†’ Recommended minimum: 30-50 records")
            response = input(f"   â†’ Continue anyway? (y/n): ")
            if response.lower() != 'y':
                print("\n   â†’ Retraining cancelled. Collect more data and try again.\n")
                return False
        
    except Exception as e:
        print(f"   âŒ Error loading training pool: {e}")
        return False
    
    # ============================================
    # 3. Combine Datasets
    # ============================================
    print("\nğŸ”— Step 3: Combining datasets...")
    
    if df_original is not None:
        # Get common columns
        common_cols = list(set(df_original.columns) & set(df_pool.columns))
        print(f"   âœ“ Common columns: {len(common_cols)}")
        
        # Ensure both have same columns in same order
        df_original_aligned = df_original[common_cols]
        df_pool_aligned = df_pool[common_cols]
        
        # Combine
        df_combined = pd.concat([df_original_aligned, df_pool_aligned], ignore_index=True)
        
        print(f"\n   ğŸ“Š Combined Dataset:")
        print(f"   âœ“ Total records: {len(df_combined)}")
        print(f"   âœ“ Original data: {len(df_original)} ({len(df_original)/len(df_combined)*100:.1f}%)")
        print(f"   âœ“ User data: {len(df_pool)} ({len(df_pool)/len(df_combined)*100:.1f}%)")
        
    else:
        df_combined = df_pool
        print(f"   âœ“ Using only user data: {len(df_combined)} records")
    
    # Show final distribution
    print(f"\n   ğŸ“Š Final Dataset:")
    print(f"   âœ“ Total records: {len(df_combined)}")
    print(f"   âœ“ Unique users: {df_combined['UserID'].nunique()}")
    
    migraine_final = df_combined['Migraine_today_0_or_1'].value_counts()
    print(f"   âœ“ Migraines: {migraine_final.get(1, 0)} ({migraine_final.get(1, 0)/len(df_combined)*100:.1f}%)")
    print(f"   âœ“ No migraines: {migraine_final.get(0, 0)} ({migraine_final.get(0, 0)/len(df_combined)*100:.1f}%)")
    
    # ============================================
    # 4. Backup Old Model
    # ============================================
    print("\nğŸ’¾ Step 4: Backing up current model...")
    
    model_file = 'models/migraine_model.pkl'
    scaler_file = 'models/scaler.pkl'
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    if os.path.exists(model_file):
        backup_model = f'models/backups/migraine_model_backup_{timestamp}.pkl'
        backup_scaler = f'models/backups/scaler_backup_{timestamp}.pkl'
        
        # Create backup directory
        os.makedirs('models/backups', exist_ok=True)
        
        shutil.copy(model_file, backup_model)
        shutil.copy(scaler_file, backup_scaler)
        
        print(f"   âœ“ Model backed up: {backup_model}")
        print(f"   âœ“ Scaler backed up: {backup_scaler}")
        print(f"   ğŸ’¡ You can restore from backup if needed")
    else:
        print(f"   â†’ No existing model to backup")
    
    # ============================================
    # 5. Train New Model
    # ============================================
    print("\nğŸ“ Step 5: Training new model...")
    print(f"   This may take a minute...\n")
    
    # Save combined data temporarily
    temp_file = 'temp_training_data.csv'
    df_combined.to_csv(temp_file, index=False)
    
    try:
        # Initialize predictor
        predictor = MigrainePredictionSystem()
        
        # Prepare data
        print("   Preparing data...")
        X, y, df_processed = predictor.prepare_data(temp_file)
        
        # Train
        print("   Training model...")
        predictor.train(X, y, df_processed)
        
        # Save
        print("   Saving new model...")
        predictor.save_model(model_file, scaler_file)
        
        print(f"\n{'='*70}")
        print("âœ… MODEL RETRAINED SUCCESSFULLY")
        print(f"{'='*70}")
        
        print(f"\nğŸ“Š Training Summary:")
        print(f"   âœ“ Model saved to: {model_file}")
        print(f"   âœ“ Scaler saved to: {scaler_file}")
        print(f"   âœ“ Trained on {len(df_combined)} records")
        print(f"   âœ“ Includes {df_combined['UserID'].nunique()} users")
        if df_original is not None:
            print(f"   âœ“ User contribution: {len(df_pool)} records ({len(df_pool)/len(df_combined)*100:.1f}%)")
        
        print(f"\nğŸ’¡ Next Steps:")
        print(f"   1. Test the updated model with test data")
        print(f"   2. Make predictions using predict_temporal()")
        print(f"   3. Continue collecting user data")
        print(f"   4. Retrain again when you have more data")
        
        print(f"\nğŸ‰ The model will now use the updated version for all predictions!\n")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Training failed: {e}")
        print(f"\nğŸ’¡ The old model is still intact and can be used.")
        
        import traceback
        print("\nError details:")
        traceback.print_exc()
        
        return False
        
    finally:
        # Clean up temp file
        if os.path.exists(temp_file):
            os.remove(temp_file)


def show_training_pool_status():
    """Show current status of training pool"""
    print("\n" + "="*70)
    print("TRAINING POOL STATUS")
    print("="*70)
    
    training_pool_file = 'user_data/training_pool.csv'
    
    if not os.path.exists(training_pool_file):
        print("\nâŒ No training pool found")
        print("   â†’ Start collecting user data with store_temporal_data()\n")
        return
    
    df = pd.read_csv(training_pool_file)
    
    print(f"\nğŸ“Š Overall Statistics:")
    print(f"   Total records: {len(df)}")
    print(f"   Unique users: {df['UserID'].nunique()}")
    
    print(f"\nğŸ“ˆ Migraine Distribution:")
    migraine_counts = df['Migraine_today_0_or_1'].value_counts()
    print(f"   Migraines (1): {migraine_counts.get(1, 0)} ({migraine_counts.get(1, 0)/len(df)*100:.1f}%)")
    print(f"   No migraines (0): {migraine_counts.get(0, 0)} ({migraine_counts.get(0, 0)/len(df)*100:.1f}%)")
    
    print(f"\nğŸ‘¥ Data per User:")
    user_counts = df['UserID'].value_counts()
    for user, count in user_counts.head(10).items():
        print(f"   {user}: {count} records")
    
    if len(user_counts) > 10:
        print(f"   ... and {len(user_counts) - 10} more users")
    
    print(f"\nğŸ’¡ Recommendations:")
    if len(df) < 30:
        print(f"   âš ï¸  Only {len(df)} records - collect at least 30 before retraining")
    elif len(df) < 100:
        print(f"   âœ“ {len(df)} records - ready for retraining!")
        print(f"   â†’ More data will improve model accuracy")
    else:
        print(f"   âœ… {len(df)} records - excellent dataset!")
        print(f"   â†’ Ready for retraining")
    
    print()


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'status':
        # Show status only
        show_training_pool_status()
    else:
        # Run retraining
        print("\nğŸš€ Starting model retraining process...")
        print("="*70)
        
        # Show current pool status first
        show_training_pool_status()
        
        # Confirm before proceeding
        print("\n" + "="*70)
        response = input("Proceed with retraining? (y/n): ")
        
        if response.lower() == 'y':
            success = retrain_model()
            
            if success:
                print("\nâœ… Retraining complete!")
            else:
                print("\nâŒ Retraining failed or cancelled")
        else:
            print("\nâ†’ Retraining cancelled\n")

